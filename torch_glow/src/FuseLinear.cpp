/**
 * Copyright (c) 2017-present, Facebook, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "FuseLinear.h"

#include <torch/csrc/jit/jit_log.h>
#include <torch/csrc/jit/passes/alias_analysis.h>
#include <torch/csrc/jit/passes/common_subexpression_elimination.h>
#include <torch/csrc/jit/passes/dead_code_elimination.h>
#include <torch/csrc/jit/passes/subgraph_rewrite.h>

namespace glow {

/// This is mainly copied from pytorch/tvm
/// This pass fuse the addmm or matmul + add generated by JIT back to linear
/// to allow direct support with Glow integration with Glow IR
/// This pass can be deleted once the JIT can emit the aten::linear in the
/// future.
void FuseLinear(std::shared_ptr<torch::jit::Graph> &graph) {
  std::string addmmPattern = R"IR(
graph(%input, %weight, %bias, %4):
  %weight_t = aten::t(%weight)
  %res = aten::addmm(%bias, %input, %weight_t, %4, %4)
  return (%res))IR";

  std::string matmulAddPattern = R"IR(
graph(%input, %weight, %bias, %4):
  %weight_t = aten::t(%weight)
  %output = aten::matmul(%input, %weight_t)
  %res = aten::add_(%output, %bias, %4)
  return (%res))IR";

  std::string mmAddPattern = R"IR(
graph(%input, %weight, %bias, %4):
  %weight_t = aten::t(%weight)
  %output = aten::mm(%input, %weight_t)
  %res = aten::add_(%output, %bias, %4)
  return (%res))IR";

  std::string fusedLinear = R"IR(
graph(%input, %weight, %bias, %4):
  %res = aten::linear(%input, %weight, %bias)
  return (%res))IR";

  std::string matmulPattern = R"IR(
graph(%input, %weight):
  %weight_t = aten::t(%weight)
  %output = aten::matmul(%input, %weight_t)
  return (%output))IR";

  std::string mmPattern = R"IR(
graph(%input, %weight):
  %weight_t = aten::t(%weight)
  %output = aten::mm(%input, %weight_t)
  return (%output))IR";

  std::string fusedLinearBiasNone = R"IR(
graph(%input, %weight):
  %bias: Tensor? = prim::Constant()
  %res = aten::linear(%input, %weight, %bias)
  return (%res))IR";

  // Replace addmm pattern to linear.
  torch::jit::SubgraphRewriter addmmToLinear;
  addmmToLinear.RegisterRewritePattern(addmmPattern, fusedLinear);
  addmmToLinear.runOnGraph(graph);

  // Replace matmul + add pattern to linear.
  torch::jit::SubgraphRewriter matmulAddToLinear;
  matmulAddToLinear.RegisterRewritePattern(matmulAddPattern, fusedLinear);
  matmulAddToLinear.runOnGraph(graph);

  // Replace mm + add pattern to linear.
  torch::jit::SubgraphRewriter mmaddToLinear;
  mmaddToLinear.RegisterRewritePattern(mmAddPattern, fusedLinear);
  mmaddToLinear.runOnGraph(graph);

  // Replace matmul with bias=None pattern to linear.
  torch::jit::SubgraphRewriter matmulToLinear;
  matmulToLinear.RegisterRewritePattern(matmulPattern, fusedLinearBiasNone);
  matmulToLinear.runOnGraph(graph);

  // Replace mm with bias=None pattern to linear.
  torch::jit::SubgraphRewriter mmToLinear;
  mmToLinear.RegisterRewritePattern(mmPattern, fusedLinearBiasNone);
  mmToLinear.runOnGraph(graph);
}
} // namespace glow

# Creating standalone executable bundles

This document provides a short description about producing executable bundles and
using it in your projects.

## Overview

A bundle is a self-contained compiled network model that can be used to execute the
model in a standalone mode without any need for any external dependencies.

The models compiled this way are usually rather compact in terms of the code size
and are well-suited even for deployment on memory constrained devices.

## Producing a bundle

It is possible to use the Glow loader to produce bundles. The bundles are
object files that can be linked with your executable.

The loader's option to produce a bundle is called `-emit-bundle`. It can be
used e.g. in the following way:

```
loader image_file -image_mode=0to1 -d network_model_name -jit -emit-bundle output_directory_name
```

The command above would compile the neural network model from the 
`network_model_directory_name` and generate a bundle consisting of two files
in the directory `output_directory_name`.

The first file is named `network_model_name.o` and contains the compiled code
of the network model. It is a regular object file that can be linked other files
in your project.

The second file is named `network_model_name.weights` and contains the weights
required to run the compiled model.

## APIs exposed by bundles

Each bundle exposes two symbols named `network_model_name` and `network_model_name_config`.


The `network_model_name` is the name of the auto-generated function that
implements the network model. This symbol always has the following signature:
```c++
extern "C" void network_model_name(uint8_t *constantWeightVars,
                                   uint8_t *mutableWeightVars,
                                   uint8_t *activations);
```
The parameters of this function are the base addresses of the memory areas for
constant weights variables, mutable weights variables (i.e. inputs and outputs) and
activations.

The `network_model_name_config` is a symbol that contains the configuration of
the compiled network. The type of this symbol is always the following struct:
```c++
struct BundleConfig {
  // Size of the constant weight variables memory area.
  size_t constantWeightVarsMemSize;
  // Size of the mutable weight variables memory area.
  size_t mutableWeightVarsMemSize;
  // Size of the activations memory area.
  size_t activationsMemSize;
};
```
This configuration is supposed to be used by the client code to allocate the
required amounts of memory for each of the memory areas, before invoking the
`network_model_name` function to run the network.


## Integrate the produced bundle into your project

To integrate the artifacts generated by the loader into your project, you 
generally need to do the following:
* You need to link with the generated object file `network_model_name.o`.
* You need to allocate the memory for constant weights variables,
mutable weights variables (i.e. inputs and outputs) and activations based on the
memory area sizes provided by `network_model_name_config`.
* You need to load the content of the auto-generated `network_model_name.weights`
file into the constant weights variables memory area.
* And need to initialize the mutable weights area with inputs (e.g. image data)
* And finally, you need to invoke the `network_model_name` function with 3 
parameters that are base addresses of the the memory areas for constant weights variables,
mutable weights variables and activations.
* After `network_model_name` has returned, you can find the results of the mutable weights
variables area. 


## A step-by-step example for the lenet_mnist network model

There is a concrete example of integrating a network model with a project.
You can find it in the `examples/compile_lenet_mnist` directory in the Glow repository.

To build and run this example, you just need to run the `build_lenet_mnist_standalone.sh` 
script in the `examples/compile_lenet_mnist` directory. You may need to adjust the
environment variables at the top to match your setup.

The script performs the following steps:
* It downloads the lenet_mnist network model in the Caffe2 format.
* It generates the bundle files using the Glow loader as described above.
  The concrete command line looks like this:
  `loader tests/images/mnist/5_1087.png -image_mode=0to1 -d lenet_mnist -jit -emit-bundle build`
  It reads the network model from `lenet_mnist` and generates the `lenet_mnist.o`
  and `lenet_mnist.weights` files into the `build` directory.
* Then it compiles the `lenet_mnist_standalone.cpp` file, which is the main file of the project.
  This source file gives a good idea about how to interface with an auto-generated bundle.
  It contains the code for interfacing with with the auto-generated bundle.
  *  It allocated the memory areas based on their memory sizes provided in `lenet_mnist_config`.
  *  Then it loads the weights from the auto-generated `lenet_mnist.weights` file.
  *  It loads the input image, pre-processes it and puts it into the mutable weight variables
     memory area.
  *  Once evertything is setup, it invokes the compiled network model by calling the
     `lenet_mnist` function from the `lenet_mnist.o` object file.
* Then it links the user-defined `lenet_mnist_standalone.o` and auto-generated `lenet_mnist.o`
  into a standalone executable file called `lenet_mnist_standalone`
* Finally, it runs this standalone executable with mnist images as inputs and outputs the
results of the network model execution.

## The Glow Lexicon

### Definitions

### A

* ANN  
  Artificial Neural Network  
  A computational framework based on a synthetic construction of a the
  biological neural network in brains.

#### C

* CNN  
  Convolutional Neural Network  
  A subtype of DNNs, using feed-forwarding.  They are most commonly applied to
  analysis of images.

* CVP  
  Constant Value Propagation  

### D

* DAG  
  Directed Acylic Graph  

* DNM  
  Do Not Merge  

* DNN  
  Deep Neural Networks  
  A neural network with multiple layers between the input and output layers.
  These work well with linear and non-linear relationships.

### G

* GEMM  
  General Matrix Multiply  

* GRU  
  Gated Recurrent Unit  
  A gating mechanism for neural networks.  They are similar to LSTM but exhibit
  better performance characteristics on smaller data sets.

### L

* LSTM  
  Long Short Term Memory  
  Units of RNNs consisting of a cell, input gate, output gate, and a forget
  gate.  It is useful to model memory, making it useful for classifying,
  processing, and predicting over temporal data.

### M

* MLP  
  Multi-Layer Perceptron  
  A class of feed-forward ANN, consisting of an input, hidden, and output
  layers.  Excluding the input, the nodes consitute a neuron in the ANN.  Using
  non-linear activation functions and back-progation allows these networks to
  distinguish between data with non-linear relationships.

### N

* NFC  
  No Functional Change  

* NFCI  
   No Functional Change Intended  

### R

* ReLU  
  Rectified Linear Unit  
  A unit with a linear activation function in the context of a DNN.  These are
  common in computer vision and speech recognition applications.

* RNN  
  Recurrent Neural Network  
  A class of neural networks where the nodes form a DAG.  It is useful to model
  temporal dynamic behaviour, making it useful for speech and handwriting
  recognition.

